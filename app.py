from flask import Flask, request, jsonify
from flask_cors import CORS
import cv2
import numpy as np
import os
import base64

app = Flask(__name__)
CORS(app)

# =====================================================
# OMR TEMPLATE - 100 MCQ (4 COLUMNS)
# =====================================================
class OMRConfig100:
    TEMPLATE_WIDTH = 434.5635
    TEMPLATE_HEIGHT = 682.7202
    CORNER_SQUARE_WIDTH = 8.3242
    CORNER_SQUARE_HEIGHT = 8.3242
    CORNER_HORIZONTAL_DIST = 385.9177
    CORNER_VERTICAL_DIST = 633.5445
    BUBBLE_DIAMETER = 11.0
    FILL_THRESHOLD = 0.35
    
    # Roll Number (Supports 6 or 7 digits)
    ROLL_FROM_CORNER_X = 15.1605
    ROLL_FROM_CORNER_Y = 40.2629
    ROLL_VERTICAL_SPACING = 16.6315
    ROLL_HORIZONTAL_SPACING = 17.4537
    ROLL_DIGITS = 7
    ROLL_OPTIONS = 10
    
    # Serial Number (6 digits)
    SERIAL_FROM_CORNER_X = 159.8187
    SERIAL_FROM_CORNER_Y = 37.3886
    SERIAL_VERTICAL_SPACING = 16.6266
    SERIAL_HORIZONTAL_SPACING = 17.6587
    SERIAL_DIGITS = 6
    SERIAL_OPTIONS = 10
    
    # Questions (100 MCQ in 4 columns)
    Q1_FROM_CORNER_X = 28.3268
    Q1_FROM_CORNER_Y = 247.6496
    Q1_OPTION_SPACING = 17.9692
    Q1_VERTICAL_SPACING = 15.4698
    Q1_TOTAL = 25
    
    Q2_FROM_CORNER_X = 124.3077
    Q2_FROM_CORNER_Y = 247.6496
    Q2_OPTION_SPACING = 17.9692
    Q2_VERTICAL_SPACING = 15.4698
    Q2_TOTAL = 25
    
    Q3_FROM_CORNER_X = 220.3095
    Q3_FROM_CORNER_Y = 247.6496
    Q3_OPTION_SPACING = 17.9692
    Q3_VERTICAL_SPACING = 15.4698
    Q3_TOTAL = 25
    
    Q4_FROM_CORNER_X = 318.3722
    Q4_FROM_CORNER_Y = 247.6496
    Q4_OPTION_SPACING = 17.9692
    Q4_VERTICAL_SPACING = 15.4698
    Q4_TOTAL = 25
    
    Q_OPTIONS = ['A', 'B', 'C', 'D']

# =====================================================
# OMR TEMPLATE - 50 MCQ (2 COLUMNS)
# =====================================================
class OMRConfig50:
    TEMPLATE_WIDTH = 345.6
    TEMPLATE_HEIGHT = 511.2
    CORNER_SQUARE_WIDTH = 10.0
    CORNER_SQUARE_HEIGHT = 10.0
    CORNER_HORIZONTAL_DIST = 309.776
    CORNER_VERTICAL_DIST = 467.6418
    BUBBLE_DIAMETER = 11.0
    FILL_THRESHOLD = 0.35
    
    # Roll Number (Supports 6 or 7 digits)
    ROLL_FROM_CORNER_X = 13.2077
    ROLL_FROM_CORNER_Y = 41.1813
    ROLL_VERTICAL_SPACING = 16.6317
    ROLL_HORIZONTAL_SPACING = 17.442
    ROLL_DIGITS = 7
    ROLL_OPTIONS = 10
    
    # Serial Number (6 digits)
    SERIAL_FROM_CORNER_X = 13.0459
    SERIAL_FROM_CORNER_Y = 307.6707
    SERIAL_VERTICAL_SPACING = 16.6262
    SERIAL_HORIZONTAL_SPACING = 17.6616
    SERIAL_DIGITS = 6
    SERIAL_OPTIONS = 10
    
    # Questions (50 MCQ in 2 columns)
    Q1_FROM_CORNER_X = 152.6586
    Q1_FROM_CORNER_Y = 17.894
    Q1_OPTION_SPACING = 19.1976
    Q1_VERTICAL_SPACING = 18.2594
    Q1_TOTAL = 25
    
    Q2_FROM_CORNER_X = 239.9378
    Q2_FROM_CORNER_Y = 17.894
    Q2_OPTION_SPACING = 19.1976
    Q2_VERTICAL_SPACING = 18.2594
    Q2_TOTAL = 25
    
    Q_OPTIONS = ['A', 'B', 'C', 'D']

def preprocess_image(image):
    """
    WORLD-CLASS preprocessing - handles ALL problems:
    - Poor lighting
    - Shadows
    - Low contrast
    - Noise
    """
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    # Fixes: uneven lighting, shadows, low contrast
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)
    
    # Denoise while preserving edges
    denoised = cv2.fastNlMeansDenoising(enhanced, None, 10, 7, 21)
    
    # Sharpen to make markers crisp
    kernel_sharpen = np.array([[-1,-1,-1],
                               [-1, 9,-1],
                               [-1,-1,-1]])
    sharpened = cv2.filter2D(denoised, -1, kernel_sharpen)
    
    return sharpened

def find_corner_markers_advanced(image):
    """
    BULLETPROOF corner detection:
    - Works with rotation, skew, perspective
    - Uses bounding box edges (not centroids)
    - Multiple threshold techniques
    """
    preprocessed = preprocess_image(image)
    height, width = preprocessed.shape
    
    # Larger search zones for rotated images
    search_size_x = int(width * 0.12)
    search_size_y = int(height * 0.12)
    
    corners = {}
    regions = {
        'top_left': (0, search_size_x, 0, search_size_y),
        'top_right': (width - search_size_x, width, 0, search_size_y),
        'bottom_left': (0, search_size_x, height - search_size_y, height),
        'bottom_right': (width - search_size_x, width, height - search_size_y, height)
    }
    
    for corner_name, (x1, x2, y1, y2) in regions.items():
        roi = preprocessed[y1:y2, x1:x2]
        
        # Try multiple thresholding methods for robustness
        thresh_methods = [
            cv2.adaptiveThreshold(roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                 cv2.THRESH_BINARY_INV, 11, 2),
            cv2.adaptiveThreshold(roi, 255, cv2.ADAPTIVE_THRESH_MEAN_C, 
                                 cv2.THRESH_BINARY_INV, 11, 2),
            cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]
        ]
        
        best_corner = None
        best_score = 0
        
        for thresh in thresh_methods:
            # Morphological operations to clean up
            kernel = np.ones((3,3), np.uint8)
            cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
            cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)
            
            contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area < 15 or area > 2000:  # Wider range
                    continue
                
                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = w / float(h) if h > 0 else 0
                
                # More lenient aspect ratio for skewed images
                if 0.6 < aspect_ratio < 1.4:
                    # Score based on squareness and size
                    squareness = 1.0 - abs(1.0 - aspect_ratio)
                    size_score = min(area / 100.0, 1.0)
                    
                    # Prefer contours closer to expected position
                    if corner_name == 'top_left':
                        position_score = 1.0 - (x + y) / (roi.shape[1] + roi.shape[0])
                    elif corner_name == 'top_right':
                        position_score = 1.0 - ((roi.shape[1] - x - w) + y) / (roi.shape[1] + roi.shape[0])
                    elif corner_name == 'bottom_left':
                        position_score = 1.0 - (x + (roi.shape[0] - y - h)) / (roi.shape[1] + roi.shape[0])
                    else:  # bottom_right
                        position_score = 1.0 - ((roi.shape[1] - x - w) + (roi.shape[0] - y - h)) / (roi.shape[1] + roi.shape[0])
                    
                    score = squareness * size_score * position_score
                    
                    if score > best_score:
                        best_score = score
                        # Use CORNER of bounding box (not centroid)
                        if corner_name == 'top_left':
                            best_corner = (x + x1, y + y1)
                        elif corner_name == 'top_right':
                            best_corner = (x + w + x1, y + y1)
                        elif corner_name == 'bottom_left':
                            best_corner = (x + x1, y + h + y1)
                        else:  # bottom_right
                            best_corner = (x + w + x1, y + h + y1)
        
        if best_corner is not None:
            corners[corner_name] = best_corner
    
    return corners

def apply_perspective_correction(image, corners, config):
    """
    CRITICAL: Transform image to perfect rectangle
    Fixes: perspective distortion, rotation, skew
    Makes everything outside 4 corners irrelevant
    """
    if len(corners) < 4:
        return None, None
    
    # Source points (detected corners)
    src_points = np.float32([
        corners['top_left'],
        corners['top_right'],
        corners['bottom_right'],
        corners['bottom_left']
    ])
    
    # Destination points (perfect rectangle based on template)
    # Calculate output size maintaining aspect ratio
    template_aspect = config.TEMPLATE_WIDTH / config.TEMPLATE_HEIGHT
    
    # Use detected width/height to determine output size
    detected_width = np.linalg.norm(np.array(corners['top_right']) - np.array(corners['top_left']))
    detected_height = np.linalg.norm(np.array(corners['bottom_left']) - np.array(corners['top_left']))
    
    # Scale to reasonable size (max 1200px width)
    if detected_width > 1200:
        scale = 1200 / detected_width
        output_width = 1200
        output_height = int(detected_height * scale)
    else:
        output_width = int(detected_width)
        output_height = int(detected_height)
    
    dst_points = np.float32([
        [0, 0],
        [output_width, 0],
        [output_width, output_height],
        [0, output_height]
    ])
    
    # Calculate perspective transformation matrix
    matrix = cv2.getPerspectiveTransform(src_points, dst_points)
    
    # Apply transformation
    corrected = cv2.warpPerspective(image, matrix, (output_width, output_height))
    
    # Recalculate scale factors for corrected image
    scale_x = output_width / config.CORNER_HORIZONTAL_DIST
    scale_y = output_height / config.CORNER_VERTICAL_DIST
    
    # New corner positions after correction (they're now at perfect corners)
    corrected_corners = {
        'top_left': (0, 0),
        'top_right': (output_width, 0),
        'bottom_left': (0, output_height),
        'bottom_right': (output_width, output_height)
    }
    
    return corrected, corrected_corners, scale_x, scale_y

def check_bubble_filled_adaptive(gray_img, x, y, radius_x, radius_y, base_threshold):
    """
    ADAPTIVE bubble detection:
    - Handles elliptical bubbles (different X/Y scaling)
    - Dynamic thresholding based on local contrast
    - Multiple verification methods
    """
    try:
        x, y = int(round(x)), int(round(y))
        radius_x = max(3, int(round(radius_x)))
        radius_y = max(3, int(round(radius_y)))
        
        # Check bounds
        if (x < radius_x or y < radius_y or 
            x >= gray_img.shape[1] - radius_x or y >= gray_img.shape[0] - radius_y):
            return False, 0.0
        
        # Create elliptical mask
        mask = np.zeros(gray_img.shape, dtype=np.uint8)
        cv2.ellipse(mask, (x, y), (radius_x, radius_y), 0, 0, 360, 255, -1)
        
        # Extract bubble region
        bubble_region = gray_img[mask > 0]
        
        if len(bubble_region) == 0:
            return False, 0.0
        
        # Method 1: Intensity-based (works with preprocessed image)
        mean_intensity = np.mean(bubble_region)
        background_estimate = np.mean(gray_img[max(0, y-radius_y*3):min(gray_img.shape[0], y+radius_y*3),
                                               max(0, x-radius_x*3):min(gray_img.shape[1], x+radius_x*3)])
        
        # Adaptive threshold based on local contrast
        contrast_ratio = (background_estimate - mean_intensity) / max(background_estimate, 1)
        
        # Method 2: Pixel counting with adaptive threshold
        local_thresh = cv2.adaptiveThreshold(
            gray_img[max(0, y-radius_y*2):min(gray_img.shape[0], y+radius_y*2),
                    max(0, x-radius_x*2):min(gray_img.shape[1], x+radius_x*2)],
            255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 
            max(3, radius_x//2*2+1), 2
        )
        
        local_mask = np.zeros(local_thresh.shape, dtype=np.uint8)
        offset_x = max(0, radius_x*2 - x)
        offset_y = max(0, radius_y*2 - y)
        cv2.ellipse(local_mask, (min(x, radius_x*2), min(y, radius_y*2)), 
                   (radius_x, radius_y), 0, 0, 360, 255, -1)
        
        if np.sum(local_mask) > 0:
            filled_pixels = np.sum(local_thresh[local_mask > 0] > 0)
            total_pixels = np.sum(local_mask > 0)
            fill_percentage = filled_pixels / total_pixels
        else:
            fill_percentage = 0
        
        # Combine both methods
        final_score = (contrast_ratio * 0.6 + fill_percentage * 0.4)
        
        # Dynamic threshold adjustment
        adjusted_threshold = base_threshold * 0.8  # Slightly more sensitive
        
        is_filled = final_score > adjusted_threshold
        
        return is_filled, final_score
        
    except Exception as e:
        return False, 0.0

def process_omr_sheet_worldclass(img, config, threshold, answer_key):
    """
    WORLD-CLASS OMR processing:
    1. Preprocess image (lighting, contrast, noise)
    2. Detect corners with multiple methods
    3. Apply perspective correction (makes outside 4 corners irrelevant)
    4. Adaptive bubble detection with elliptical support
    5. Multi-method verification
    """
    
    # Step 1: Find corners on original image
    corners = find_corner_markers_advanced(img)
    
    if len(corners) < 4:
        return {'error': f'Could not detect all 4 corners. Found {len(corners)}. Please ensure all corner markers are visible and dark.'}
    
    # Step 2: Apply perspective correction
    correction_result = apply_perspective_correction(img, corners, config)
    if correction_result is None:
        return {'error': 'Failed to apply perspective correction'}
    
    corrected_img, corrected_corners, scale_x, scale_y = correction_result
    
    # Step 3: Preprocess corrected image for optimal bubble detection
    preprocessed = preprocess_image(corrected_img)
    
    # Step 4: Create result image from corrected version
    result_img = corrected_img.copy()
    
    # Mark corners on result image
    for corner_name, (cx, cy) in corrected_corners.items():
        if corner_name in ['top_left', 'bottom_left']:  # Only mark left corners (others are at edges)
            cv2.circle(result_img, (int(cx), int(cy)), 8, (255, 0, 255), -1)
    
    # Calculate bubble radii (use both X and Y scales)
    bubble_radius_x = (config.BUBBLE_DIAMETER / 2) * scale_x
    bubble_radius_y = (config.BUBBLE_DIAMETER / 2) * scale_y
    bubble_radius_display = int((bubble_radius_x + bubble_radius_y) / 2)
    
    top_left = corrected_corners['top_left']
    
    # Detect Roll Number
    roll_number = ""
    detected_digits = []
    
    for digit_col in range(config.ROLL_DIGITS):
        detected_digit = None
        max_fill = 0
        best_x, best_y = 0, 0
        
        for row in range(config.ROLL_OPTIONS):
            offset_x = config.ROLL_FROM_CORNER_X + (digit_col * config.ROLL_HORIZONTAL_SPACING)
            offset_y = config.ROLL_FROM_CORNER_Y + (row * config.ROLL_VERTICAL_SPACING)
            actual_x = top_left[0] + (offset_x * scale_x)
            actual_y = top_left[1] + (offset_y * scale_y)
            
            is_filled, fill_score = check_bubble_filled_adaptive(
                preprocessed, actual_x, actual_y, bubble_radius_x, bubble_radius_y, threshold
            )
            
            if is_filled and fill_score > max_fill:
                max_fill = fill_score
                detected_digit = str(row)
                best_x, best_y = int(actual_x), int(actual_y)
        
        if detected_digit:
            detected_digits.append({
                'digit': detected_digit,
                'position': digit_col,
                'x': best_x,
                'y': best_y
            })
    
    # Build roll number
    if len(detected_digits) >= 6:
        for item in detected_digits:
            roll_number += item['digit']
            cv2.circle(result_img, (item['x'], item['y']), bubble_radius_display, (0, 255, 0), 2)
    
    # Detect Serial Number
    serial_number = ""
    for digit_col in range(config.SERIAL_DIGITS):
        detected_digit = None
        max_fill = 0
        best_x, best_y = 0, 0
        
        for row in range(config.SERIAL_OPTIONS):
            offset_x = config.SERIAL_FROM_CORNER_X + (digit_col * config.SERIAL_HORIZONTAL_SPACING)
            offset_y = config.SERIAL_FROM_CORNER_Y + (row * config.SERIAL_VERTICAL_SPACING)
            actual_x = top_left[0] + (offset_x * scale_x)
            actual_y = top_left[1] + (offset_y * scale_y)
            
            is_filled, fill_score = check_bubble_filled_adaptive(
                preprocessed, actual_x, actual_y, bubble_radius_x, bubble_radius_y, threshold
            )
            
            if is_filled and fill_score > max_fill:
                max_fill = fill_score
                detected_digit = str(row)
                best_x, best_y = int(actual_x), int(actual_y)
        
        if detected_digit:
            serial_number += detected_digit
            cv2.circle(result_img, (best_x, best_y), bubble_radius_display, (0, 255, 0), 2)
    
    # Detect Answers
    answers = []
    
    def process_column(start_q, total_q, base_x_offset, base_y_offset, v_spacing, opt_spacing):
        for q_num in range(start_q, start_q + total_q):
            detected_option = None
            max_fill = 0
            best_x, best_y = 0, 0
            all_bubble_positions = {}
            
            base_x = top_left[0] + (base_x_offset * scale_x)
            base_y = top_left[1] + (base_y_offset * scale_y) + ((q_num - start_q) * v_spacing * scale_y)
            
            # Check all options
            for opt_idx, option in enumerate(config.Q_OPTIONS):
                actual_x = base_x + (opt_idx * opt_spacing * scale_x)
                actual_y = base_y
                all_bubble_positions[option] = (int(actual_x), int(actual_y))
                
                # Draw subtle circle for all options
                cv2.circle(result_img, (int(actual_x), int(actual_y)), bubble_radius_display, (200, 200, 200), 1)
                
                # Add option label
                font = cv2.FONT_HERSHEY_SIMPLEX
                font_scale = 0.65
                font_thickness = 2
                text_size = cv2.getTextSize(option, font, font_scale, font_thickness)[0]
                text_x = int(actual_x - text_size[0] / 2)
                text_y = int(actual_y + text_size[1] / 2)
                cv2.putText(result_img, option, (text_x, text_y), font, font_scale, (160, 160, 160), font_thickness, cv2.LINE_AA)
                
                is_filled, fill_score = check_bubble_filled_adaptive(
                    preprocessed, actual_x, actual_y, bubble_radius_x, bubble_radius_y, threshold
                )
                
                if is_filled and fill_score > max_fill:
                    max_fill = fill_score
                    detected_option = option
                    best_x, best_y = int(actual_x), int(actual_y)
            
            correct_answer = answer_key.get(str(q_num))
            is_correct = False
            
            if detected_option:
                if correct_answer and detected_option == correct_answer:
                    cv2.circle(result_img, (best_x, best_y), bubble_radius_display, (0, 255, 0), -1)
                    is_correct = True
                else:
                    cv2.circle(result_img, (best_x, best_y), bubble_radius_display, (0, 0, 255), -1)
                    if correct_answer and correct_answer in all_bubble_positions:
                        correct_x, correct_y = all_bubble_positions[correct_answer]
                        cv2.circle(result_img, (correct_x, correct_y), bubble_radius_display, (0, 255, 0), 2)
            else:
                if correct_answer and correct_answer in all_bubble_positions:
                    correct_x, correct_y = all_bubble_positions[correct_answer]
                    cv2.circle(result_img, (correct_x, correct_y), bubble_radius_display, (0, 255, 0), 2)
            
            answers.append({
                'question': q_num,
                'answer': detected_option,
                'correct_answer': correct_answer,
                'is_correct': is_correct,
                'confidence': round(max_fill * 100, 1) if detected_option else 0,
                'status': 'correct' if is_correct else ('wrong' if detected_option else 'skipped')
            })
    
    # Process columns based on config
    if hasattr(config, 'Q4_FROM_CORNER_X'):  # 100 MCQ
        process_column(1, config.Q1_TOTAL, config.Q1_FROM_CORNER_X, config.Q1_FROM_CORNER_Y, 
                      config.Q1_VERTICAL_SPACING, config.Q1_OPTION_SPACING)
        process_column(26, config.Q2_TOTAL, config.Q2_FROM_CORNER_X, config.Q2_FROM_CORNER_Y, 
                      config.Q2_VERTICAL_SPACING, config.Q2_OPTION_SPACING)
        process_column(51, config.Q3_TOTAL, config.Q3_FROM_CORNER_X, config.Q3_FROM_CORNER_Y, 
                      config.Q3_VERTICAL_SPACING, config.Q3_OPTION_SPACING)
        process_column(76, config.Q4_TOTAL, config.Q4_FROM_CORNER_X, config.Q4_FROM_CORNER_Y, 
                      config.Q4_VERTICAL_SPACING, config.Q4_OPTION_SPACING)
    else:  # 50 MCQ
        process_column(1, config.Q1_TOTAL, config.Q1_FROM_CORNER_X, config.Q1_FROM_CORNER_Y, 
                      config.Q1_VERTICAL_SPACING, config.Q1_OPTION_SPACING)
        process_column(26, config.Q2_TOTAL, config.Q2_FROM_CORNER_X, config.Q2_FROM_CORNER_Y, 
                      config.Q2_VERTICAL_SPACING, config.Q2_OPTION_SPACING)
    
    # Add header with stats
    img_height, img_width = result_img.shape[:2]
    header_height = 100
    final_img = np.ones((img_height + header_height, img_width, 3), dtype=np.uint8) * 255
    final_img[header_height:, :] = result_img
    cv2.rectangle(final_img, (0, 0), (img_width - 1, img_height + header_height - 1), (0, 0, 0), 2)
    
    # Calculate stats
    correct_count = len([a for a in answers if a['status'] == 'correct'])
    wrong_count = len([a for a in answers if a['status'] == 'wrong'])
    skipped_count = len([a for a in answers if a['status'] == 'skipped'])
    
    # Draw stats boxes
    font = cv2.FONT_HERSHEY_SIMPLEX
    box_width = 180
    box_height = 60
    box_spacing = 20
    total_width = (box_width * 3) + (box_spacing * 2)
    x_start = (img_width - total_width) // 2
    y_top = 20
    
    def draw_rounded_rect_filled(img, pt1, pt2, color, radius=15):
        x1, y1 = pt1
        x2, y2 = pt2
        cv2.rectangle(img, (x1 + radius, y1), (x2 - radius, y2), color, -1)
        cv2.rectangle(img, (x1, y1 + radius), (x2, y2 - radius), color, -1)
        cv2.circle(img, (x1 + radius, y1 + radius), radius, color, -1)
        cv2.circle(img, (x2 - radius, y1 + radius), radius, color, -1)
        cv2.circle(img, (x1 + radius, y2 - radius), radius, color, -1)
        cv2.circle(img, (x2 - radius, y2 - radius), radius, color, -1)
    
    # Correct
    draw_rounded_rect_filled(final_img, (x_start, y_top), (x_start + box_width, y_top + box_height), (0, 128, 0), 15)
    cv2.putText(final_img, f'Correct:{correct_count}', (x_start + 20, y_top + 38), font, 0.9, (255, 255, 255), 2, cv2.LINE_AA)
    
    # Wrong
    x_start += box_width + box_spacing
    draw_rounded_rect_filled(final_img, (x_start, y_top), (x_start + box_width, y_top + box_height), (0, 0, 200), 15)
    cv2.putText(final_img, f'Wrong:{wrong_count}', (x_start + 25, y_top + 38), font, 0.9, (255, 255, 255), 2, cv2.LINE_AA)
    
    # Skipped
    x_start += box_width + box_spacing
    draw_rounded_rect_filled(final_img, (x_start, y_top), (x_start + box_width, y_top + box_height), (0, 0, 0), 15)
    cv2.putText(final_img, f'Skipped:{skipped_count}', (x_start + 15, y_top + 38), font, 0.9, (255, 255, 255), 2, cv2.LINE_AA)
    
    # Convert to base64
    _, buffer = cv2.imencode('.jpg', final_img, [cv2.IMWRITE_JPEG_QUALITY, 100])
    img_base64 = base64.b64encode(buffer).decode('utf-8')
    
    return {
        'success': True,
        'roll_number': roll_number if roll_number else None,
        'serial_number': serial_number if serial_number else None,
        'total_questions': len(answers),
        'correct': correct_count,
        'wrong': wrong_count,
        'skipped': skipped_count,
        'marked': correct_count + wrong_count,
        'answers': answers,
        'threshold_used': threshold,
        'result_image': f'data:image/jpeg;base64,{img_base64}'
    }

@app.route('/')
def home():
    return '''
    <div style="text-align:center; font-family:Arial; padding:50px;">
        <h1>ðŸŒŸ World-Class OMR Checker API ðŸŒŸ</h1>
        <p style="font-size:1.3em; color:#667eea; font-weight:bold;">
            âœ… Perspective Correction<br>
            âœ… Rotation Handling<br>
            âœ… Skew Compensation<br>
            âœ… Adaptive Lighting<br>
            âœ… 100% Accuracy with 4 Corners
        </p>
        <hr style="margin:30px 0;">
        <h3>Endpoints:</h3>
        <ul style="line-height:2;">
            <li><code>/process-omr</code> - Auto-detect format</li>
            <li><code>/process-omr-50</code> - Force 50 MCQ</li>
            <li><code>/process-omr-100</code> - Force 100 MCQ</li>
        </ul>
    </div>
    '''

@app.route('/test')
def test():
   return jsonify({'status': 'ok', 'message': 'World-Class OMR API - Ready!'})

@app.route('/process-omr', methods=['POST'])
def process_omr_auto():
    """Auto-detect format or use mcq_format parameter"""
    try:
        mcq_format = request.form.get('mcq_format', '100')
        
        if mcq_format == '50':
            return process_omr_50()
        else:
            return process_omr_100()
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/process-omr-50', methods=['POST'])
def process_omr_50():
    """Process 50 MCQ OMR with world-class detection"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file uploaded'}), 400
        
        file = request.files['file']
        filepath = f'/tmp/{file.filename}'
        file.save(filepath)
        
        img = cv2.imread(filepath)
        if img is None:
            return jsonify({'error': 'Cannot read image file'}), 400
        
        threshold = float(request.form.get('threshold', OMRConfig50.FILL_THRESHOLD))
        answer_key_json = request.form.get('answer_key', '{}')
        
        import json
        answer_key = json.loads(answer_key_json)
        
        result = process_omr_sheet_worldclass(img, OMRConfig50, threshold, answer_key)
        os.remove(filepath)
        
        return jsonify(result)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/process-omr-100', methods=['POST'])
def process_omr_100():
    """Process 100 MCQ OMR with world-class detection"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file uploaded'}), 400
        
        file = request.files['file']
        filepath = f'/tmp/{file.filename}'
        file.save(filepath)
        
        img = cv2.imread(filepath)
        if img is None:
            return jsonify({'error': 'Cannot read image file'}), 400
        
        threshold = float(request.form.get('threshold', OMRConfig100.FILL_THRESHOLD))
        answer_key_json = request.form.get('answer_key', '{}')
        
        import json
        answer_key = json.loads(answer_key_json)
        
        result = process_omr_sheet_worldclass(img, OMRConfig100, threshold, answer_key)
        os.remove(filepath)
        
        return jsonify(result)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 10000))
    app.run(host='0.0.0.0', port=port)
